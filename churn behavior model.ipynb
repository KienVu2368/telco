{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zero/anaconda/envs/fastai-cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/zero/anaconda/envs/fastai-cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/zero/anaconda/envs/fastai-cpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.init import kaiming_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai.datasets import *\n",
    "from fastai.tabular import *\n",
    "from fastai.basic_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai.basic_train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai.callbacks import *\n",
    "from fastai.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#data.to_pickle('telco.pkl')\n",
    "telco = pd.read_pickle('telco.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = telco['churn'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "telco.drop('churn', axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(telco, y, test_size=0.2, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train = (x_train - x_train.mean()) / (x_train.max() - x_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_val = (x_val - x_val.mean()) / (x_val.max() - x_val.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train = (y_train - y_train.mean()) / (y_train.max() - y_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_val = (y_val - y_val.mean()) / (y_val.max() - y_val.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train[:100].copy()\n",
    "y_train = y_train[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_val = x_val[:100].copy()\n",
    "y_val = y_val[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tn = [t for t in telco.columns if t.endswith('tn')]\n",
    "tn_1 = [t for t in telco.columns if t.endswith('tn_1')]\n",
    "tn_2 = [t for t in telco.columns if t.endswith('tn_2')]\n",
    "tn_3 = [t for t in telco.columns if t.endswith('tn_3')]\n",
    "tn_4 = [t for t in telco.columns if t.endswith('tn_4')]\n",
    "tn_5 = [t for t in telco.columns if t.endswith('tn_5')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train_behave = np.stack([x_train[t] for t in [tn_5, tn_4, tn_3, tn_2, tn_1]])#.transpose([1,0,2])\n",
    "x_val_behave = np.stack([x_val[t] for t in [tn_5, tn_4, tn_3, tn_2, tn_1]])#.transpose([1,0,2])\n",
    "y_train_behave = np.stack([x_train[tn]])[0]\n",
    "y_val_behave = np.stack([x_val[tn]])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class telcodataset(DatasetBase):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = np.float32(y)\n",
    "    \n",
    "    def __len__(self)->int: return len(self.y)\n",
    "    def __getitem__(self, idx): return self.x[:,idx,:], self.y[idx]\n",
    "    \n",
    "    @property\n",
    "    def c(self)->int: 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class telcodatabunch(DataBunch):\n",
    "    \"Create a `DataBunch` suitable for tabular data.\"\n",
    "    @classmethod\n",
    "    def from_df(cls, path, x_train, y_train, x_val, y_val, **kwargs):\n",
    "        \"Create a `DataBunch` from train/valid/test dataframes.\"\n",
    "        train_ds = telcodataset(x_train, y_train)\n",
    "        valid_ds = telcodataset(x_val, y_val)\n",
    "        datasets = [train_ds, valid_ds]\n",
    "        return cls.create(*datasets, path=path, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = telcodatabunch.from_df('/', x_train_behave, y_train_behave, x_val_behave, y_val_behave, bs = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = iter(db.train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x, y = next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 25])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# architechture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 996,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class telcoRNNCore(nn.Module):\n",
    "    \"AWD-LSTM/QRNN inspired by https://arxiv.org/abs/1708.02182.\"\n",
    "\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, \n",
    "                 #vocab_sz:int, \n",
    "                 #emb_sz:int,\n",
    "                 input_sz:int,\n",
    "                 n_hid:int, \n",
    "                 n_layers:int, \n",
    "                 #pad_token:int, \n",
    "                 #bidir:bool=False,\n",
    "                 hidden_p:float=0.2, \n",
    "                 input_p:float=0.6, \n",
    "                 #embed_p:float=0.1, \n",
    "                 weight_p:float=0.5, \n",
    "                 #qrnn:bool=False\n",
    "                ):\n",
    "\n",
    "        super().__init__()\n",
    "        self.bs = 1\n",
    "        self.n_hid,self.n_layers = n_hid,n_layers\n",
    "        #self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)\n",
    "        #self.encoder_dp = EmbeddingDropout(self.encoder, embed_p)\n",
    "        #self.encoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        \n",
    "        self.input_dp = RNNDropout(input_p)\n",
    "        \n",
    "        self.rnns = [nn.LSTM(input_sz if l == 0 else n_hid, (n_hid if l != n_layers-1 else input_sz), 1) for l in range(n_layers)]\n",
    "        #self.rnns = [nn.LSTM(input_sz if l == 0 else n_hid, n_hid, 1) for l in range(n_layers)]\n",
    "        self.rnns = [WeightDropout(rnn, weight_p) for rnn in self.rnns]\n",
    "        self.rnns = torch.nn.ModuleList(self.rnns)\n",
    "        \n",
    "        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])\n",
    "        self.att_seq = attention_seq(ip_sz = 25, op_sz=input_sz,  drop = 0.2) #att_ip_drop\n",
    "        self.att_fea = attention_fea(ip_sz = 25, op_sz = 25)\n",
    "\n",
    "    def forward(self, input):\n",
    "        #sl,bs = input.size()\n",
    "        #if bs!=self.bs:\n",
    "        #    self.bs=bs\n",
    "        #    self.reset()\n",
    "        raw_output = self.input_dp(input)\n",
    "        #new_hidden,raw_outputs,outputs = [],[],[]\n",
    "        raw_outputs,outputs = [],[]\n",
    "        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):\n",
    "            raw_output, new_h = rnn(raw_output.float()) #, self.hidden[l]\n",
    "            #new_hidden.append(new_h)\n",
    "            raw_outputs.append(raw_output)\n",
    "            if l != self.n_layers - 1: raw_output = hid_dp(raw_output)\n",
    "            outputs.append(raw_output)\n",
    "        \n",
    "        output = outputs[-1]\n",
    "        att_seq, att_seq_m = self.att_seq(output, input)\n",
    "        att_fea, att_fea_m = self.att_fea(output)\n",
    "        \n",
    "        #self.hidden = to_detach(new_hidden)\n",
    "        return output, att_seq, att_seq_m, att_fea, att_fea_m\n",
    "\n",
    "#     def _one_hidden(self, l:int):\n",
    "#         \"Return one hidden state.\"\n",
    "#         nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz)//self.ndir\n",
    "#         return self.weights.new(self.ndir, self.bs, nh).zero_()\n",
    "\n",
    "#     def reset(self):\n",
    "#         \"Reset the hidden states.\"\n",
    "#         [r.reset() for r in self.rnns if hasattr(r, 'reset')]\n",
    "#         self.weights = next(self.parameters()).data\n",
    "#         if self.qrnn: self.hidden = [self._one_hidden(l) for l in range(self.n_layers)]\n",
    "#         else: self.hidden = [(self._one_hidden(l), self._one_hidden(l)) for l in range(self.n_layers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## linear decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 997,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class linear_block(nn.Module):\n",
    "    def __init__(self, ip_sz, op_sz, drop = None, bias = True, initrange = None, linear = True):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.op_sz = op_sz\n",
    "        self.ln = nn.Linear(ip_sz, op_sz, bias = bias)\n",
    "        kaiming_normal_(self.ln.weight.data)\n",
    "        if initrange is not None: self.ln.weight.data.uniform_(-initrange, initrange)\n",
    "        if bias: self.ln.bias.data.zero_()\n",
    "        if drop is not None:\n",
    "            self.bn = nn.BatchNorm1d(op_sz)\n",
    "            self.drp = nn.Dropout(drop)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.ln(x) if self.linear else F.relu(self.drp(self.bn(self.ln(x))))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class LinearDecoder(nn.Module):\n",
    "    \"To go on top of a RNNCore module and create a Language Model.\"\n",
    "\n",
    "    initrange=0.1\n",
    "\n",
    "    def __init__(self, n_out:int, n_hid:int, output_p:float, bias:bool=True):\n",
    "        super().__init__()\n",
    "        self.concat_lyrs = linear_block(175, 32, 0.2 , linear= False) #concat_drop\n",
    "        \n",
    "        self.decoder = linear_block(32, 25, drop = 0.2, initrange = self.initrange, bias=bias)\n",
    "        #self.decoder.weight.data.uniform_(-self.initrange, self.initrange)\n",
    "        self.output_dp = RNNDropout(output_p)\n",
    "        #if bias: self.decoder.bias.data.zero_()\n",
    "        #if tie_encoder: self.decoder.weight = tie_encoder.weight\n",
    "\n",
    "    def forward(self, input):\n",
    "        output, att_seq, att_seq_m, att_fea, att_fea_m = input\n",
    "        output = self.output_dp(output)\n",
    "        output = output.view(output.size(0), -1)\n",
    "        x = self.concat_lyrs(torch.cat([output, att_seq, att_fea], 1))        \n",
    "        #decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        decoded = self.decoder(x)\n",
    "        return decoded.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class PoolingLinearClassifier(nn.Module):\n",
    "    \"Create a linear classifier with pooling.\"\n",
    "\n",
    "    def __init__(self, output_p):\n",
    "        super().__init__()\n",
    "        self.concat_lyrs = linear_block(250, 32, 0.2 , linear= False) #concat_drop\n",
    "        self.decoder = linear_block(32, 1, drop = 0.2)\n",
    "        self.output_dp = RNNDropout(output_p)\n",
    "\n",
    "    def pool(self, x:Tensor, bs:int, is_max:bool):\n",
    "        \"Pool the tensor along the seq_len dimension.\"\n",
    "        f = F.adaptive_max_pool1d if is_max else F.adaptive_avg_pool1d\n",
    "        #return f(x.permute(1,2,0), (1,)).view(bs,-1)\n",
    "        return f(x.permute(0,2,1), (1,)).view(bs,-1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        output, att_seq, att_seq_m, att_fea, att_fea_m = input\n",
    "        bs = output.size(0)\n",
    "        avgpool = self.pool(output, bs, False)\n",
    "        mxpool = self.pool(output, bs, True)\n",
    "        \n",
    "        output = self.output_dp(output)\n",
    "        output = output.view(output.size(0), -1)        \n",
    "\n",
    "        \n",
    "        x = self.concat_lyrs(torch.cat([output, att_seq, att_fea, avgpool, mxpool], 1))        \n",
    "        #decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        decoded = self.decoder(x).float()\n",
    "        \n",
    "        return decoded.view(-1), att_seq_m, att_fea_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_p(*sz): return nn.Parameter(torch.randn(sz)/math.sqrt(sz[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class attention_fea(nn.Module):\n",
    "    def __init__(self, ip_sz = 64, op_sz = 36, drop = 0.2):\n",
    "        super().__init__()\n",
    "        self.w = rand_p(ip_sz, op_sz)\n",
    "        self.ln = linear_block(op_sz, op_sz, drop)\n",
    "        self.v = rand_p(op_sz, op_sz)\n",
    "             \n",
    "    def forward(self, outp):\n",
    "        we = outp@self.w\n",
    "        u = torch.tanh(we)\n",
    "        at = F.softmax((u@self.v).sum(1), 1)\n",
    "        xa = self.ln(at) #.double()\n",
    "        return xa, at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class attention_seq(nn.Module):\n",
    "    def __init__(self, ip_sz = 64, op_sz = 36, drop = 0.2):\n",
    "        super().__init__()\n",
    "        self.w = rand_p(ip_sz, op_sz)\n",
    "        self.ln = linear_block(op_sz, op_sz, drop)\n",
    "        self.v = rand_p(op_sz, op_sz)\n",
    "              \n",
    "    def forward(self, outp, inp):\n",
    "        we = outp@self.w\n",
    "        u = torch.tanh(we)\n",
    "        at = F.softmax(u@self.v, 1)\n",
    "        xa = self.ln((at.double()*inp).sum(1))\n",
    "        return xa, at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# behavior learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def telco_lm_split(model):\n",
    "    \"Split a RNN `model` in groups for differential learning rates.\"\n",
    "    groups = [[rnn, dp] for rnn, dp in zip(model[0].rnns, model[0].hidden_dps)]\n",
    "    groups.append([model[0].input_dp, model[1]])\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def rnn_classifier_split(model):\n",
    "    \"Split a RNN `model` in groups for differential learning rates.\"\n",
    "    groups = [[rnn, dp] for rnn, dp in zip(model[0].rnns, model[0].hidden_dps)]\n",
    "    groups.append([model[1]])\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class RNNLearner(Learner):\n",
    "    \"Basic class for a Learner in RNN.\"\n",
    "    def __init__(self,\n",
    "                 path,\n",
    "                 data:DataBunch, \n",
    "                 model, \n",
    "                 #bptt:int=70, \n",
    "                 split_func=None, \n",
    "                 clip:float=None,\n",
    "                 adjust:bool=False, \n",
    "                 alpha:float=2., \n",
    "                 beta:float=1., \n",
    "                 **kwargs):\n",
    "        super().__init__(data, model, path = path, model_dir = 'models', **kwargs)\n",
    "        self.path = path\n",
    "        #self.callbacks.append(RNNTrainer(self, bptt, alpha=alpha, beta=beta, adjust=adjust))\n",
    "        if clip: self.callback_fns.append(partial(GradientClipping, clip=clip))\n",
    "        if split_func: self.split(split_func)\n",
    "        self.metrics = None #[accuracy]\n",
    "\n",
    "    def save_encoder(self, name:str):\n",
    "        \"Save the encoder to `name` inside the model directory.\"\n",
    "        torch.save(self.model[0].state_dict(), self.path/f'{name}.pth')\n",
    "\n",
    "    def load_encoder(self, name:str):\n",
    "        \"Load the encoder `name` from the model directory.\"\n",
    "        self.model[0].load_state_dict(torch.load(self.path/f'{name}.pth'))\n",
    "        self.freeze()\n",
    "\n",
    "    @classmethod\n",
    "    def language_model(cls,\n",
    "                       path,\n",
    "                       data:DataBunch, \n",
    "                       #bptt:int=70, \n",
    "                       #emb_sz:int=400,\n",
    "                       input_sz = 25,\n",
    "                       nh:int=1150, \n",
    "                       nl:int=3, \n",
    "                       #pad_token:int=1,\n",
    "                       drop_mult:float=1., \n",
    "                       #tie_weights:bool=True, \n",
    "                       bias:bool=True, \n",
    "                       #qrnn:bool=False, \n",
    "                       #pretrained_model=None,\n",
    "                       #pretrained_fnames:OptStrTuple=None, \n",
    "                       **kwargs):\n",
    "        \"Create a `Learner` with a language model.\"\n",
    "        dps = np.array([0.25, 0.1, 0.2, 0.02, 0.15]) * drop_mult\n",
    "        \n",
    "        rnn_enc = telcoRNNCore(input_sz = input_sz, n_hid=nh, n_layers=nl, input_p=dps[0], weight_p=dps[2], hidden_p=dps[4])\n",
    "        #lnr_dec = LinearDecoder(n_out = input_sz, n_hid = input_sz, output_p= dps[1], bias= bias)\n",
    "        lnr_dec = LinearDecoder(n_out = input_sz, n_hid = input_sz*5, output_p= dps[1], bias= bias)\n",
    "        \n",
    "        #vocab_size = data.train_ds.vocab_size\n",
    "        model = SequentialRNN(rnn_enc, lnr_dec)\n",
    "        learn = cls(path, data, model, split_func=telco_lm_split, **kwargs) #bptt,\n",
    "        return learn\n",
    "    \n",
    "    @classmethod\n",
    "    def classifier(cls,\n",
    "                   path,\n",
    "                   data,\n",
    "                   input_sz = 25,\n",
    "                   #bptt:int=70, \n",
    "                   #max_len:int=70*20, \n",
    "                   #emb_sz:int=400, \n",
    "                   nh:int=1150, \n",
    "                   nl:int=3,\n",
    "                   #lin_ftrs:Collection[int]=None, \n",
    "                   ps:Collection[float]=None, \n",
    "                   #pad_token:int=1,\n",
    "                   drop_mult:float=1., \n",
    "                   #qrnn:bool=False, \n",
    "                   **kwargs):\n",
    "        \"Create a RNN classifier.\"\n",
    "        dps = np.array([0.4,0.5,0.05,0.3,0.4]) * drop_mult\n",
    "        #if lin_ftrs is None: lin_ftrs = [50]\n",
    "        if ps is None:  ps = [0.1]\n",
    "        rnn_enc = telcoRNNCore(input_sz = input_sz, n_hid=nh, n_layers=nl, input_p=dps[0], weight_p=dps[2], hidden_p=dps[4])\n",
    "        #lnr_dec = LinearDecoder(n_out = input_sz, n_hid = input_sz, output_p= dps[1], bias= bias)\n",
    "        lnr_dec = PoolingLinearClassifier(output_p= dps[1])\n",
    "        model = SequentialRNN(rnn_enc, lnr_dec)\n",
    "        learn = cls(path, data, model, split_func=rnn_classifier_split, **kwargs) #bptt,\n",
    "        return learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 825,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner = RNNLearner.language_model(Path('./models'), db, input_sz = 25, nh = 8, nl = 3, drop_mult = 0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def loss(input, target):\n",
    "    #pdb.set_trace()\n",
    "    input, att_seq_m, att_fea_m = input\n",
    "    input = input.float()\n",
    "    target = target.float()\n",
    "    return F.mse_loss(input, target, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.loss_func = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.metrics = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429092371e824a61a435dab8a3c4dd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=4), HTML(value='0.00% [0/4 00:00<00:00]'))), HTML(value='epoch  train loss  valid loss<p>')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [80 x 8], m2: [25 x 25] at /opt/conda/conda-bld/pytorch-nightly-cpu_1538636779972/work/aten/src/TH/generic/THTensorMath.cpp:932",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-791-5cf1fd4b86fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_one_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/fastai/train.py\u001b[0m in \u001b[0;36mfit_one_cycle\u001b[0;34m(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m     17\u001b[0m     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,\n\u001b[1;32m     18\u001b[0m                                         pct_start=pct_start, **kwargs))\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcyc_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlr_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mLearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_lr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_it\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_div\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, lr, wd, callbacks)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_fns\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlistify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,\n\u001b[0;32m--> 137\u001b[0;31m             callbacks=self.callbacks+callbacks)\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreate_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mFloats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m->\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(epochs, model, loss_func, opt, data, callbacks, metrics)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/fastai/basic_train.py\u001b[0m in \u001b[0;36mloss_batch\u001b[0;34m(model, xb, yb, loss_func, opt, cb_handler)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_listy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0myb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcb_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_loss_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-780-b886eb16b481>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0matt_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_seq_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0matt_fea\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matt_fea_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matt_fea\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/fastai-cpu/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-783-4150bb1dbe1e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, outp, mtrx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtrx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mwe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutp\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [80 x 8], m2: [25 x 25] at /opt/conda/conda-bld/pytorch-nightly-cpu_1538636779972/work/aten/src/TH/generic/THTensorMath.cpp:932"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "learner.save_encoder('behavior_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x_train_class = np.stack([x_train[t] for t in [tn_5, tn_4, tn_3, tn_2, tn_1, tn]])#.transpose([1,0,2])\n",
    "x_val_class = np.stack([x_val[t] for t in [tn_5, tn_4, tn_3, tn_2, tn_1, tn]])#.transpose([1,0,2])\n",
    "y_train_class = np.array(y_train)\n",
    "y_val_class = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "db = telcodatabunch.from_df('/', x_train_class, y_train_class, x_val_class, y_val_class, bs = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = RNNLearner.classifier(Path('./models'), db, input_sz = 25, nh = 8, nl = 3, drop_mult = 0.5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(input, target):\n",
    "    input, att_seq_m, att_fea_m = input\n",
    "    #pdb.set_trace()\n",
    "    input = input.float()\n",
    "    target = target.float()\n",
    "    return F.binary_cross_entropy_with_logits(input, target, reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1002,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.loss_func = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.metrics = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86c1367d03d4c14b5ef26699774e54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>VBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, max=5), HTML(value='0.00% [0/5 00:00<00:00]'))), HTML(value='epoch  train loss  valid loss<p>')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 00:05\n",
      "epoch  train loss  valid loss\n",
      "1      10.872232   22.735891   (00:01)\n",
      "2      10.195671   21.863991   (00:01)\n",
      "3      9.480897    21.200529   (00:01)\n",
      "4      8.851356    20.401417   (00:01)\n",
      "5      8.474024    18.498566   (00:01)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.fit_one_cycle(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
